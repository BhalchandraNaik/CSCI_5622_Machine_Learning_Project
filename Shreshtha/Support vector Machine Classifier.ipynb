{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processes: 12\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')  # to suppress some matplotlib deprecation warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "input_path = \"/Users/blue/Machine Learning\"\n",
    "train_simplified_path = input_path + \"/train_simplified/\"\n",
    "\n",
    "train_simplified = os.listdir(train_simplified_path)\n",
    "number_of_processes = os.cpu_count()\n",
    "print(\"Number of processes:\", number_of_processes)\n",
    "BASE_SIZE = 256\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Util functions which are used to convert sketch into image of size*size dimention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_generator_xd(dataframe, size, lw=6, time_color=True, ):\n",
    "    dataframe['drawing'] = dataframe['drawing'].apply(json.loads)\n",
    "    x = np.zeros((len(dataframe), size * size))\n",
    "    for i, raw_strokes in enumerate(dataframe.drawing.values):\n",
    "        x[i, :] = draw_cv2(raw_strokes, size=size, lw=lw, time_color=time_color)\n",
    "    x = preprocess_input(x).astype(np.float32)\n",
    "    return x, dataframe['word'].values\n",
    "\n",
    "\n",
    "def draw_cv2(raw_strokes, size=256, lw=6, time_color=True):\n",
    "    img = np.zeros((BASE_SIZE, BASE_SIZE), np.uint8)\n",
    "    for t, stroke in enumerate(raw_strokes):\n",
    "        for i in range(len(stroke[0]) - 1):\n",
    "            color = 255 - min(t, 10) * 13 if time_color else 255\n",
    "            _ = cv2.line(img, (stroke[0][i], stroke[1][i]),\n",
    "                         (stroke[0][i + 1], stroke[1][i + 1]), color, lw)\n",
    "    if size != BASE_SIZE:\n",
    "        return cv2.resize(img, (size, size)).reshape(-1)\n",
    "    else:\n",
    "        return img.reshape(-1)\n",
    "    \n",
    "    \n",
    "def get_lambda(value):\n",
    "    return lambda x: value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to prepare the test and training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_name, label, value, rows=100):\n",
    "    data = pd.read_csv(file_name, index_col='key_id', nrows=rows)\n",
    "    data['word'] = data['word'].replace(label, value, regex=True)\n",
    "    return data\n",
    "\n",
    "\n",
    "# print(train_simplified)\n",
    "def get_small_sample(dir_listing, sample_size=5, rows=100, random_sample=False):\n",
    "    sample_files = None\n",
    "    if random_sample:\n",
    "        sample_files = random.sample(dir_listing, sample_size)\n",
    "    else:\n",
    "        sample_files = dir_listing[:sample_size]\n",
    "\n",
    "    print(\"Samples in Account :\", sample_files)\n",
    "    mapping = dict()\n",
    "    reverse_mapping = dict()\n",
    "\n",
    "    data_set = []\n",
    "    for i, sample in enumerate(sample_files):\n",
    "        print(\"Reading sample\", sample)\n",
    "        ex_name_raw = sample.split('.')[0]\n",
    "        ex_name = ex_name_raw.replace(' ', '_')\n",
    "        mapping[ex_name] = i\n",
    "        reverse_mapping[i] = ex_name\n",
    "        data_set.append(read_file(train_simplified_path + sample, ex_name_raw, i, rows))\n",
    "    return data_set, mapping, reverse_mapping\n",
    "\n",
    "\n",
    "def split_data(list_data_frames, ts= 0.1):\n",
    "    training_frames = []\n",
    "    testing_frames = []\n",
    "    for df in list_data_frames:\n",
    "        train_df, test_df = train_test_split(df, test_size=ts, shuffle=False)\n",
    "        training_frames.append(train_df)\n",
    "        testing_frames.append(test_df)\n",
    "    return pd.concat(training_frames), pd.concat(testing_frames)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the test and training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples in Account : ['line.csv', 'bucket.csv', 'bus.csv', 'cello.csv', 'ocean.csv', 'truck.csv', 'camouflage.csv', 'harp.csv', 'telephone.csv', 'stairs.csv', 'star.csv', 'guitar.csv', 'sandwich.csv', 'sun.csv', 'feather.csv', 'leaf.csv', 'toilet.csv', 'strawberry.csv', 'waterslide.csv', 'bottlecap.csv']\n",
      "Reading sample line.csv\n",
      "Reading sample bucket.csv\n",
      "Reading sample bus.csv\n",
      "Reading sample cello.csv\n",
      "Reading sample ocean.csv\n",
      "Reading sample truck.csv\n",
      "Reading sample camouflage.csv\n",
      "Reading sample harp.csv\n",
      "Reading sample telephone.csv\n",
      "Reading sample stairs.csv\n",
      "Reading sample star.csv\n",
      "Reading sample guitar.csv\n",
      "Reading sample sandwich.csv\n",
      "Reading sample sun.csv\n",
      "Reading sample feather.csv\n",
      "Reading sample leaf.csv\n",
      "Reading sample toilet.csv\n",
      "Reading sample strawberry.csv\n",
      "Reading sample waterslide.csv\n",
      "Reading sample bottlecap.csv\n",
      "Data prepared\n"
     ]
    }
   ],
   "source": [
    "no_of_classes = 20\n",
    "no_of_rows = 500\n",
    "\n",
    "small_data_set, y_mapping, rev_y_mapping = get_small_sample(train_simplified, sample_size=no_of_classes,rows=no_of_rows)\n",
    "train_set, test_set = split_data(small_data_set, ts = 0.1)\n",
    "\n",
    "name_to_number = lambda x: y_mapping[x]\n",
    "number_to_name = lambda x: rev_y_mapping[x]\n",
    "\n",
    "x_train, y_train = image_generator_xd(train_set, 64)\n",
    "x_test, y_test = image_generator_xd(test_set, 64)\n",
    "print(\"Data prepared\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random forest Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with linear kernal\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
      "     verbose=0)\n",
      "Linear SVC accuracy:  0.317\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM with linear kernal\")\n",
    "lsvc = LinearSVC(random_state=1)\n",
    "lsvc.fit(x_train, y_train)\n",
    "print(lsvc)\n",
    "y_pred_lsvc = lsvc.predict(x_test)\n",
    "acc_lsvc = accuracy_score(y_test, y_pred_lsvc)\n",
    "print('Linear SVC accuracy: ', acc_lsvc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing grid search to tune the paramerters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with RBF Kernal\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=1, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Gaussian Radial Basis Function SVC Accuracy:  0.603\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM with RBF Kernal\")\n",
    "svc = SVC(kernel='rbf', random_state=1)\n",
    "svc.fit(x_train, y_train)\n",
    "print(svc)\n",
    "y_pred_svc = svc.predict(x_test)\n",
    "acc_svc = accuracy_score(y_test, y_pred_svc)\n",
    "print('Gaussian Radial Basis Function SVC Accuracy: ', acc_svc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
